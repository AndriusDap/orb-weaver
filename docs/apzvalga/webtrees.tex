Straipsnyje \kclong{trees} naudojamas paprastesnis duomenų rinkinys ir siūlomas sprendimų medžio naudojimas kenkėjiškoms svetainėms identifikuoti pagal įvairias jų savybes.

Internetinės svetainės naudoja įvairius pajamų generavimo metodus. Dalis jų yra neteisėti ir kenkia svetainių naudotojams. Tokių svetainių identifikavimas ir blokavimas leidžia apsaugoti naudotojus nuo kenkėjiškos programinės įrangos. Įprasti metodai naudoja pavojingų svetainių sąrašus, tačiau šie sąrašai yra baigtiniai, naujos svetainės į juos pridedamos ne iš karto\cite{webtrees}. Alternatyva blokuojamų sąrašų sudarymui yra mašininio mokymo modelis kuris gali atpažinti pavojingas svetaines pagal jų adresą.

\ktutexfigure{apzvalga/webtrees_process.tex}{Metodo schema}

Metodo pritaikymo schema yra vaizduojama \vref{fig:apzvalga/webtrees_process.tex} diagramoje. Svetainių klasifikavimui naudojamas C4.5 sprendimų medis.


Sprendimų medis yra vienas iš klasifikavimo modelių \cite{c45}. Klasifikavimas vykdomas sukuriant testus, kurie atitinka medžio viršūnes. Įrašai yra tikrinami pagal viršūnes atitinkančius testus, pagal testo rezultatą einama per medį kol pasiekiama kurią nors klasę atitinkanti medžio viršūnė \cite{trees}. Algoritmas C4.5 yra paremtas ankstesniu, ID3 medžio formavimo algoritmu \cite{c45}.

Sprendimų medis formuojamas dviem etapais. Pirma suformuojamas medis, vėliau jis yra supaprastinamas siekiant sumažinti jo sudėtingumą ir galimai padidinti jo tikslumą \cite{c45}. Medį sudarantys formuojami testai. Testas tikrina vieną iš atributų. Atributas ir jo vertė parenkami siekiant maksimizuoti informacijos išlošį gaunamą padalinant duomenų rinkinį į du segmentus \cite{Wu2008}.

 Informacijos išlošis skaičiuojamas kaip duomenų rinkinio entropijos skirtumas prieš ir po padalinimo. Viso duomenų rinkinio S entropija gaunama \cite{c45}
\begin{equation}\label{eq:entropija}
entropija(S) = \sum_{j=1}^{k} \frac{freq(C_j, S)}{|S|} \times log_2\Big(\frac{freq(C_j, S)}{|S|}\Big)  bitai.
\end{equation}
kur $freq(C_j, S)$ yra $S$ aibės elementų skaičius kurie priklauso klasei $C_i$. Rinkinį $T$ padalinus į rinkinius $T_1, T_2, ... , T_n$ naudojant testą $X$ kuris padalina rinkinį į $n$ grupių skaičiuojama pasverta entropija $entropija_X(T)$ \cite{c45}
\begin{equation}\label{eq:entropija_x}
entropija_x(T) = \sum_{i=1}^{n} \frac{|T_i|}{|T|} \times entropija(T_i)
\end{equation}
dydis
\begin{equation}\label{eq:išlošis}
    išlo \check sis(X) = entropija(T) - entropija_X(T)
\end{equation}
nusako kiek informacijos gaunama, dalinant rinkinį $T$ naudojant testą $X$. Šis dydis yra skaičiuojamas visiems galimiems testams. Radus didžiausią vertę kuriamas testas ir pridedamas į formuojamą medį. Toliau tai kartojama su gautomis $n$ medžio šakų, taip suformuojant visą medį, iki kol pasiekiamos konkrečios klasės medžio viršūnėse ir nebėra atributų pagal kuriuos būtų galima atlikti testus \cite{c45}.

Algoritmas C4.5 yra vystomas iš ID3 \cite{Wu2008}. Šis, atnaujintas, metodas prideda papildomas savybes. Medžio formavimo metu testuose atsižvelgiama į neegzistuojančias reikšmes, pridedama galimybė naudoti ne tik testus su diskrečiomis reikšmėmis, bet ir su tęstinėmis reikšmėmis. Taip pat pridedamas ir medžio mažinimo žingsnis, kuris atliekamas suformavus visą medį. Tai ne tik supaprastina medį bet ir mažina persimokymą \cite{c45}. Taikant metodą interneto svetainių klasifikavimio atveju yra svarbus tik šio algoritmo minimizavimo aspektas, nes tęstinės bei neegzistuojančios reikšmės nepasitaiko duotame duomenų rinkinyje.

Medžio minimizavimui galimi keli metodai. Vieni naudoja papildomą duomenų rinkinį, pagal kurį aptinkamos medžio šakos suformuotos dėl pirminio mokymo duomenų rinkinio persimokymo. Alternatyvus metodas kuris nereikalauja papildomų duomenų mokymui yra naudojamas C4.5 algoritme, jis stengiasi prognozuoti klaidų kiekį šakoje, laikant kad duomenys yra pasiskirstę pagal binominį skirstinį. Tada skaičiuojama, kuriuo atveju klaidų yra daugiau, ar kai medžio šaka pakeista lapu atitinkančiu tam tikrą klasę ar kai paliekama egzistuojanti šaka.

Sprendimų medžiai turi ir tam tikrų apribojimų \cite{c45}. Laikant kad visi tiriamos aibės elementai yra išsidėstę Euklido erdvėje, sprendimų medis klases sukurs išskirdamas stačiakampius regionus erdvėje. Tai reiškia, kad ne stačiakampio formos klasteriai bus imituojami kelių stačiakampių, taip prarandant dalį tikslumo ir didinant sudėtingumą.

Siūloma alternatyva \cite{c45} yra dirbtinių neuronų tinklai, jie gali pasiekti didesnį tikslumą nei sprendimų medžiai, rezultatas yra gana nesudėtingai pasiekiamas \cite{c45}, tačiau jiems suformuoti reikia žymiai daugiau skaičiavimo resursų.

Klasifikavimui naudojamos leksikografinės svetainių adreso sąvybės bei serverio savybės. Naudojamos svetainės serverio savybės:
\begin{enumerate}[label=\arabic*.]
    \item Duomenų centro vieta;
    \item Domeno savininko kontaktinė informacija;
    \item Domeno registracijos data;
    \item Domeno informacijos atnaujinimo data;
    \item Svetainės spartinančiųjų atmintinių informacijos saugojimo laikas;
    \item Domeno valstybės kodas;
    \item Ryšio su serveriu pralaidumas.
\end{enumerate}

Naudojamos leksikografinės savybės yra formuojamos iš svetainės universalaus adreso (URL). Jis yra dalinamas į segmentus, kuriuos skiria įvairūs simboliai bei skyrybos ženklai. Šie segmentai tampa dvireikšmėmis adreso savybėmis.

Modeliui apmokyti naudotas duomenų rinkinys surinktas iš kelių skirtingų šaltinių. Naudoti 5000 URL iš kurių 1676 yra kenkėjiškų svetainių adresai.

Apmokant modelį naudota kryžminė patikra, 10\% duomenų skiriama testavimo duomenų imčiai. Naudoti matai tikslumui įvertinti yra jautrumas, tikslumas, specifiškumas, AUC metrika. Kryžminė patikra naudota dėl mažo duomenų rinkinio. Jos algoritmas aprašomas \ktualgoref{cross}.

\begin{ktualgo}{cross}{Kryžminės validacijos algoritmas}
   \For{validacijos žingsniams i}
        \State{Atskirti i-tąjį validacijos duomenų rinkinį}
        \State{Apmokyti modelį su likusiais duomenimis}
        \State{Įvertinti modelį su i-tąja validacijos imtimi}
        \State{Išsaugoti validacijos rezultatus}
    \EndFor{}
    \State{Pateikti vidutines validacijų reikšmes}
\end{ktualgo}

Naudoti tikslumo matai yra:
\begin{equation}\label{eq:jautrumas}
jautrumas = {TP \over {TP + FN}} \cdot 100
\end{equation}

\begin{equation}\label{eq:tikslumas}
tikslumas = {TP \over {jautrumas + specifi \check skumas}} \cdot 100
\end{equation}

\begin{equation}\label{eq:specifiškumas}
specifi \check skumas = {TN \over {TN + FP}} \cdot 100
\end{equation}

kur \textit{TN} yra tikrų neigiamų, \textit{TP} tikrų teigiamų, \textit{FP} klaidingai teigiamų, \textit{FN} klaidingai
neigiamų klasifikavimų skaičius.

\begin{ktutable}{webtrees_rezultatas}{Straipsnyje pateikiami matavimų rezultatai}
    \begin{tabular}{| l | c | c | c | c | }
     \hline
     \diagbox{Kategorija}{Metrika} & Tikslumas & Jautrumas & Specifiškumas & AUC \\ \hline
     Nekenksmingos & 98.3\% & 96.4\% & 96.5\% & 0.985 \\ \hline
     Kenksmingos & 92.9\% & 96.4\% & 96.5\% & 0.985 \\ \hline
    \end{tabular}
\end{ktutable}

Matavimų rezultatai pateikiami \vref{tab:webtrees_rezultatas} lentelėje. Rezultatai yra itin aukšti. Tai gali būti lemiama duomenų rinkinio formavimo specifikos. Mokymo duomenų rinkiniui naudojamos svetainės iš egzistuojančių juodųjų sąrašų. Modelis sugeba išmokti tik jau aptiktų svetainių savybių, naudojant jį po tam tikro laiko tarpo, kai kenksmingos svetainės yra atnaujintos atsižvelgiant į egzistuojančius juoduosius sąrašus modelio rezultatai turėtų prastėti. Taip pat naudojamas duomenų rinkinys yra nedidelis, tai leidžia medžiui gerai prisitaikyti prie jame esančių duomenų.